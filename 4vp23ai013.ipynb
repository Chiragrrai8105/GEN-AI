{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2937cf3a",
   "metadata": {},
   "source": [
    "### EXP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85ae0e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model=api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcd8325e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('swimming', 0.8071774244308472), ('swimmers', 0.7504438757896423), ('swims', 0.7454535365104675), ('surfing', 0.7409682273864746), ('biking', 0.7364492416381836), ('swam', 0.731138288974762), ('jumping', 0.7218191027641296), ('diving', 0.7187682390213013), ('kayaking', 0.7121444344520569), ('snowboarding', 0.7015390992164612)]\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(positive=['walking','swim'],negative=['walk']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b190254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'king'+'man'-'woman' is closest to:('queen', 0.8523604273796082)\n"
     ]
    }
   ],
   "source": [
    "result=model.most_similar(positive=['king','woman'],negative=['man'])\n",
    "print(f\"'king'+'man'-'woman' is closest to:{result[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f68ae25",
   "metadata": {},
   "source": [
    "### EXP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751ec157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained word vectors...\n",
      "\n",
      "Word Relationship :king-man+women\n",
      "Most similar words to the result(excluding input words):\n",
      "queen:0.535494\n",
      "kings:0.516231\n",
      "queens:0.499536\n",
      "kumaris:0.492385\n",
      "princes:0.462333\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "print(\"Loading pre-trained word vectors...\")\n",
    "word_vectors=api.load(\"word2vec-google-news-300\")\n",
    "def explore_word_relationships(word1,word2,word3):\n",
    "    try:\n",
    "        vec1=word_vectors[word1]\n",
    "        vec2=word_vectors[word2]\n",
    "        vec3=word_vectors[word3]\n",
    "        result_vector=vec1-vec2+vec3\n",
    "        similar_words=word_vectors.similar_by_vector(result_vector,topn=10)\n",
    "        filtered_words=[(word,similarity) for word,similarity in similar_words if word not in {word1,word2,word3}]\n",
    "        print(f\"\\nWord Relationship :{word1}-{word2}+{word3}\")\n",
    "        print(\"Most similar words to the result(excluding input words):\")\n",
    "        for word,similarity in filtered_words[:5]:\n",
    "            print(f\"{word}:{similarity:4f}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Error:{e} not found in the vocabulary.\")\n",
    "explore_word_relationships(\"king\",\"man\",\"women\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee36fad",
   "metadata": {},
   "source": [
    "### EXP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4adf6228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "935a38ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb46792c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m vector \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([model[word]\u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words])\n\u001b[1;32m      3\u001b[0m fig \u001b[38;5;241m=\u001b[39m make_subplots(rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,subplot_titles \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPCA Visualization\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt-SNE Visualization\u001b[39m\u001b[38;5;124m'\u001b[39m),horizontal_spacing \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m pca_vcetor \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[38;5;241m.\u001b[39mfit_transform(vector)\n\u001b[1;32m      5\u001b[0m tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,perplexity\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m250\u001b[39m , random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      6\u001b[0m tsne_vector \u001b[38;5;241m=\u001b[39m tsne\u001b[38;5;241m.\u001b[39mfit_transform(vector)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pca' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "words = ['queen','throne','prince','daughter','elizabeth','princess','kingdom','monarch','eldest','widow']\n",
    "vector = np.array([model[word]for word in words])\n",
    "fig = make_subplots(rows = 1,cols=2,subplot_titles = ('PCA Visualization','t-SNE Visualization'),horizontal_spacing = 0.1)\n",
    "pca=PCA(n_components=2)\n",
    "pca_vcetor = pca.fit_transform(vector)\n",
    "tsne = TSNE(n_components=2,perplexity= 5, n_iter = 250 , random_state = 42)\n",
    "tsne_vector = tsne.fit_transform(vector)\n",
    "fig.add_trace(go.Scatter(x = pca_vcetor[:,0],y = pca_vcetor[:,1],mode = 'markers+text',text = words, textposition = \"top center\",marker = dict(size = 12,color = 'purple',symbol = 'diamond',line = dict(color='gold',width=2)),name = 'Words'),row=1,col=1)\n",
    "fig.add_trace(go.Scatter(x = tsne_vector[:,0],y = tsne_vector[:,1],mode = 'markers+text',text = words, textposition = \"top center\",marker = dict(size = 12,color = 'purple',symbol = 'diamond',line = dict(color='gold',width=2)),name = 'Words'),row=1,col=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac3411b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
